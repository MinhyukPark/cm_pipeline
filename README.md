# cm_pipeline
Modular pipeline for testing and using an improved version of CM for generating well-connected clusters.
- [cm\_pipeline](#cm_pipeline)
  - [Overview](#overview)
  - [Input and Usage Instructions](#input-and-usage-instructions)
    - [JSON Input Documentation](#json-input-documentation)
  - [Requirements](#requirements)
    - [UIUC EngrIT Systems](#uiuc-engrit-systems)
  - [Setup and Running Instructions](#setup-and-running-instructions)
    - [How to Clone CM for any particular version](#how-to-clone-cm-for-any-particular-version)
  - [Output Files](#output-files)
  - [Citation](#citation)

## Overview 
![cm_pipeline Overview](figures/cm_pp_overview.png)

## Setup and Running Instructions
### Setup via Cloning
- Clone the cm_pipeline repository
- Activate the venv which has the necessary packages 
- Run `pip install -r requirements.txt`
- Edit the fields of the `pipeline.json` file to reflect your inputs and requirements. Please refer to the documentation on how to write the `pipeline.json` file.
- Run `python -m main pipeline.json`
### How to Clone CM for any particular version
Simply run the following
```
git clone -b v<version #> https://github.com/illinois-or-research-analytics/cm_pipeline.git .
```
### Setup via pip install (Beta)
Simply run `pip install git+https://github.com/illinois-or-research-analytics/cm_pipeline`

## Input and Usage Instructions
- The input to the pipeline script is a [pipeline.json](pipeline.json) file. **NOTE** that you can use any other json file as input as long as it fits the requirements in the documentation.
- Description of the supported key-value pairs in the config file can be found here [pipeline_template.json](docs/pipeline_template.json)
- Edit the fields of the `pipeline.json` file to reflect your inputs and requirements.
- Run `python -m main pipeline.json`
### JSON Input Documentation
- Please refer to the [json format documentation](docs/json_format.md) on how to write the `pipeline.json` file.

## Customizing the Pipeline
### Adding Your Own Clustering Methods
- Please refer to the [cluster methods documentation](docs/cluster_methods.md) on how to insert your own clustering methods.
### Creating Your Own Pipeline Stages
- Please refer to the [pipeline stages documentation](docs/pipeline_stages.md) on how to create your own pipeline stages.

## Requirements
- Create a python venv with 3.9 or above version. We are using python3.9
     - Activate the venv and run "pip install -r requirements.txt"
- `cmake` version `3.2.0` and above should be installed.
- `python39-devel` or higher should be installed, e.g., dnf install python39-devel 
- `openmpi` and `gcc` of any version
     - In our analysis, `openmpi 4.2.0` and `gcc 9.2.0` were used. The code works with gcc 8.5 too in an Oracle Linux 8 environment.
### UIUC EngrIT Systems
- These instructions are specific for users on an EngrIT cluster (such as Valhalla or the Campus Cluster) under the University of Illinois at Urbana-Champaign
- You can get all the needed packages to run the pipeline via the following commands
```bash
module load python3/3.10.0
module load cmake/3.25.1
module load gcc/9.2.0
module load openmpi/4.0.1
```
**NOTE: These need to be loaded not just on installation but on execution of the CM pipeline**

## Output Files
- The commands executed during the workflow are captured in `{output_dir}/{run_name}-{timestamp}/commands.sh`. This is the shell script generated by the pipeline that is run to generate outputs. 
- The output files generated during the workflow are stored in the folder `{output_dir}/{run_name}-{timestamp}/`
- The descriptive analysis files can be found in the folder `{output_dir}/{run_name}-{timestamp}/analysis` with the `*.csv` file for each of the resolution values.

<!--
- The commands executed during the workflow are captured in `./logs/executed-cmds/executed-cmds-timestamp.txt`
- The Output files generated during the workflow are stored in the folder `user-defined-output-dir/network_name-cm-pp-output-timestamp/`
- The descriptive analysis files can be found in the folder `user-defined-output-dir/network_name-cm-pp-output-timestamp/analysis` with the `*.csv` file for each of the resolution values.

## Note:
- At present the new version of `CM` is by default executed in quiet mode. If you want to run it in verbose mode then 
comment out the [--quiet](https://github.com/illinois-or-research-analytics/cm_pipeline/blob/main/source/connectivity_modifier_new.py#:~:text=cm.py%22%2C-,%22%2D%2Dquiet%22%2C,-%22%2Di%22%2C) argument in [source/connectivity_modifier_new.py](source/connectivity_modifier_new.py). Better still, request the ability to turn it on and off easily.

## References
- [https://engineeringfordatascience.com/posts/python_logging/](https://engineeringfordatascience.com/posts/python_logging/)
- [https://docs.python.org/3/library/logging.config.html#logging-config-fileformat](https://docs.python.org/3/library/logging.config.html#logging-config-fileformat)
-->

## Citation
```bibtex
@misc{cm_pipe2023,
  author = {Vidya Kamath and Vikram Ramavarapu and Fabio Ayres, and George Chacko},
  title = {Connectivity Modifier Pipeline},
  howpublished = {\url{https://github.com/illinois-or-research-analytics/cm_pipeline}},
  year={2023},
}
```

<!--
## TODOs:
- Add fraction of clusters untouched by the central CM module of pipeline in the analysis file.
- Mechanism to sync the scripts used within cm_pipeline with the latest changes.
- Add more log messages in the source code for different levels (Currently INFO, DEBUG, ERROR log messages are added). 
-->

