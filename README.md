# cm_pipeline

Customizable modular pipeline for testing and using an improved version of CM for generating well-connected clusters.

- [cm\_pipeline](#cm_pipeline)
  - [Overview](#overview)
  - [Setup and Running Instructions](#setup-and-running-instructions)
    - [Setup via Cloning](#setup-via-cloning)
    - [Setup via pip install (Beta)](#setup-via-pip-install-beta)
  - [Input and Usage Instructions](#input-and-usage-instructions)
  - [Documentation](#documentation)
    - [JSON Input Documentation](#json-input-documentation)
    - [Customizing the Pipeline](#customizing-the-pipeline)
  - [Requirements](#requirements)
    - [UIUC EngrIT Systems](#uiuc-engrit-systems)
  - [Output Files](#output-files)
  - [Archive](#archive)
  - [Citation](#citation)

## Overview

**TODO: Change this figure**
![cm_pipeline Overview](figures/cm_pp_overview.png)

## Setup and Running Instructions

### Setup via Cloning

- Clone the cm_pipeline repository
- Activate the venv which has the necessary packages
- Run `pip install -r requirements.txt`
- Edit the fields of the `pipeline.json` file to reflect your inputs and requirements. Please refer to the documentation on how to write the `pipeline.json` file.
- Run `python -m main pipeline.json`

### Setup via pip install (Beta)

Simply run `pip install git+https://github.com/illinois-or-research-analytics/cm_pipeline`

## Input and Usage Instructions

- The input to the pipeline script is a [pipeline.json](pipeline.json) file. **NOTE** that you can use any other json file as input as long as it fits the requirements in the documentation.
- Description of the supported key-value pairs in the config file can be found here [pipeline_template.json](docs/pipeline_template.json)
- Edit the fields of the `pipeline.json` file to reflect your inputs and requirements.
- Run `python -m main pipeline.json`

## Documentation

### JSON Input Documentation

- Please refer to the [json format documentation](docs/json_format.md) on how to write the `pipeline.json` file.

### Customizing the Pipeline

- The CM Pipeline also allows for users to add their own pipeline stages and clustering methods.
- Please refer to the [customization documentation](docs/pipeline_customization.md) on how to modify the code to allow for your own pipeline stages and .

## Requirements

- Create a python venv with 3.9 or above version. We are using python3.9
  - Activate the venv and run "pip install -r requirements.txt"
- `cmake` version `3.2.0` and above should be installed.
- `python39-devel` or higher should be installed, e.g., dnf install python39-devel
- `openmpi` and `gcc` of any version
  - In our analysis, `openmpi 4.2.0` and `gcc 9.2.0` were used. The code works with gcc 8.5 too in an Oracle Linux 8 environment.

### UIUC EngrIT Systems

- These instructions are specific for users on an EngrIT cluster (such as Valhalla or the Campus Cluster) under the University of Illinois at Urbana-Champaign
- You can get all the needed packages to run the pipeline via the following commands

```bash
module load python3/3.10.0
module load cmake/3.25.1
module load gcc/9.2.0
module load openmpi/4.0.1
```

- **NOTE: These need to be loaded not just on installation but on execution of the CM pipeline**

## Output Files

- The commands executed during the workflow are captured in `{output_dir}/{run_name}-{timestamp}/commands.sh`. This is the shell script generated by the pipeline that is run to generate outputs.
- The output files generated during the workflow are stored in the folder `{output_dir}/{run_name}-{timestamp}/`
- The descriptive analysis files can be found in the folder `{output_dir}/{run_name}-{timestamp}/analysis` with the `*.csv` file for each of the resolution values.

## Archive

- [View Old Release Notes](https://github.com/illinois-or-research-analytics/cm_pipeline/releases)

## Citation

```bibtex
@misc{cm_pipe2023,
  author = {Vikram Ramavarapu, Vidya Kamath, Fabio Ayres, and George Chacko},
  title = {Connectivity Modifier Pipeline},
  howpublished = {\url{https://github.com/illinois-or-research-analytics/cm_pipeline}},
  year={2023},
}
```

<!--
## TODOs:
- Add fraction of clusters untouched by the central CM module of pipeline in the analysis file.
- Mechanism to sync the scripts used within cm_pipeline with the latest changes.
- Add more log messages in the source code for different levels (Currently INFO, DEBUG, ERROR log messages are added). 
-->
